{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_btc.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yJuycwBmK4ss",
        "AFfQuQf0kWzT",
        "E7fk-6q_JBwg",
        "Dhn37Vq7K8vp",
        "DDUupONTK1nL",
        "hXDNL7l2I7d4",
        "C3HJtXIG39gp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N0EyqtdYPUa1"
      },
      "source": [
        "# Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OnJQN5ZkPUa2",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as utils\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvuNT6g8NkGY",
        "colab_type": "code",
        "outputId": "8b6f111b-94f2-4d1c-bb80-1d935ce0f6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LHfXJv19PUbK"
      },
      "source": [
        "# Device config\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm37V9goA5-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\") # PyTorch v0.4.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caOTV5E5aLf5",
        "colab_type": "text"
      },
      "source": [
        "# K-Fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osMPi4-LI45G",
        "colab_type": "text"
      },
      "source": [
        "## Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJuycwBmK4ss",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b485NEQsQylN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def tryint(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except ValueError:\n",
        "        return s\n",
        "     \n",
        "def alphanum_key(s):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "def sort_nicely(l):\n",
        "    \"\"\" Sort the given list in the way that humans expect.\n",
        "    \n",
        "    amazing <3 RegExp\n",
        "    \"\"\"\n",
        "    l.sort(key=alphanum_key)\n",
        "    return l\n",
        "\n",
        "def load_matrices(combination):\n",
        "    model_type = combination[0]\n",
        "    mode = combination[1]\n",
        "    INPUT_SIZE_CNN = 25 if model_type == 'keywords_clusters' else 126 if 'custom' in model_type else 500\n",
        "    \n",
        "    train_classes, train_user_data, train_matrices, train_dates, train_btc_meta_data, train_classes_t = None, None, None, None, None, None\n",
        "    base_str = '/content/gdrive/My Drive/projects/data/btc/{}/{}/train/'.format(model_type, mode)\n",
        "    files = os.listdir(base_str)\n",
        "    for train_file in sort_nicely(files):\n",
        "        if 'btc' in train_file:\n",
        "            temp = np.load(base_str + train_file)\n",
        "            if train_btc_meta_data is None:\n",
        "                train_btc_meta_data = temp\n",
        "            else:\n",
        "                train_btc_meta_data = np.concatenate((train_btc_meta_data, temp), axis=0)\n",
        "        elif 'tc_up' in train_file:\n",
        "            temp = np.load(base_str + train_file)\n",
        "            if train_classes_t is None:\n",
        "                train_classes_t = temp\n",
        "            else:\n",
        "                train_classes_t = np.concatenate((train_classes_t, temp), axis=0)\n",
        "        elif 'c_up' in train_file:\n",
        "            temp = np.load(base_str + train_file)\n",
        "            if train_classes is None:\n",
        "                train_classes = temp\n",
        "            else:\n",
        "                train_classes = np.concatenate((train_classes, temp), axis=0)\n",
        "        elif 'md_up' in train_file:\n",
        "            temp = np.load(base_str + train_file)\n",
        "            if train_user_data is None:\n",
        "                train_user_data = temp\n",
        "            else:\n",
        "                train_user_data = np.vstack((train_user_data, temp))\n",
        "        elif 'dp_up' in train_file:\n",
        "            temp = np.load(base_str + train_file)\n",
        "            if train_matrices is None:\n",
        "                train_matrices = temp\n",
        "            else:\n",
        "                train_matrices = np.vstack((train_matrices, temp))\n",
        "        elif 'dt_up' in train_file:\n",
        "            temp = np.load(base_str + train_file)\n",
        "            if train_dates is None:\n",
        "                train_dates = temp\n",
        "            else:\n",
        "                train_dates = np.concatenate((train_dates, temp), axis=0)\n",
        "    print(train_classes.shape, train_user_data.shape, train_matrices.shape, train_dates.shape, train_btc_meta_data.shape, train_classes_t.shape)\n",
        "    test_classes, test_user_data, test_matrices, test_dates, test_btc_meta_data, test_classes_t = None, None, None, None, None, None\n",
        "    base_str = '/content/gdrive/My Drive/projects/data/btc/{}/{}/test/'.format(model_type, mode)\n",
        "\n",
        "    for test_file in sort_nicely(os.listdir(base_str)):\n",
        "        if 'btc' in test_file:\n",
        "            temp = np.load(base_str + test_file)\n",
        "            if test_btc_meta_data is None:\n",
        "                test_btc_meta_data = temp\n",
        "            else:\n",
        "                test_btc_meta_data = np.concatenate((test_btc_meta_data, temp), axis=0)\n",
        "        elif 'tc_up' in test_file:\n",
        "            temp = np.load(base_str + test_file)\n",
        "            if test_classes_t is None:\n",
        "                test_classes_t = temp\n",
        "            else:\n",
        "                test_classes_t = np.concatenate((test_classes_t, temp), axis=0)\n",
        "        elif 'c_up' in test_file:\n",
        "            temp = np.load(base_str + test_file)\n",
        "            if test_classes is None:\n",
        "                test_classes = temp\n",
        "            else:\n",
        "                test_classes = np.concatenate((test_classes, temp), axis=0)\n",
        "        elif 'md_up' in test_file:\n",
        "            temp = np.load(base_str + test_file)\n",
        "            if test_user_data is None:\n",
        "                test_user_data = temp\n",
        "            else:\n",
        "                test_user_data = np.vstack((test_user_data, temp))\n",
        "        elif 'dp_up' in test_file:\n",
        "            temp = np.load(base_str + test_file)\n",
        "            if test_matrices is None:\n",
        "                test_matrices = temp\n",
        "            else:\n",
        "                test_matrices = np.vstack((test_matrices, temp))\n",
        "        elif 'dt_up' in test_file:\n",
        "            temp = np.load(base_str + test_file)\n",
        "            if test_dates is None:\n",
        "                test_dates = temp\n",
        "            else:\n",
        "                test_dates = np.concatenate((test_dates, temp), axis=0)\n",
        "  \n",
        "    # Normalize\n",
        "    # Re-assign tokens for userIds as this makes normalization easier (no precision errors).\n",
        "    unique_users = np.unique(np.concatenate((np.unique(train_user_data[:,-1]), np.unique(test_user_data[:,-1]))))\n",
        "    user_ids = {}\n",
        "    for i, v in enumerate(unique_users):\n",
        "        user_ids[v] = (i+1)\n",
        "\n",
        "    for i, v in enumerate(train_user_data):\n",
        "        train_user_data[i,-1] = user_ids[v[-1]]\n",
        "\n",
        "    for i, v in enumerate(test_user_data):\n",
        "        test_user_data[i,-1] = user_ids[v[-1]]\n",
        "\n",
        "    # Remove train/test users that are not in both sets.\n",
        "    indices = []\n",
        "    test_user_ids = np.unique(test_user_data[:,-1])\n",
        "    for i in range(len(train_user_data[:,-1])):\n",
        "        if train_user_data[i,-1] not in test_user_ids:\n",
        "            indices.append(i)\n",
        "\n",
        "    len(indices) / len(train_user_data[:,-1])\n",
        "    \n",
        "    train_matrices = np.delete(train_matrices, indices, axis=0)\n",
        "    train_classes_t = np.delete(train_classes_t, indices)\n",
        "    train_classes = np.delete(train_classes, indices)\n",
        "    train_user_data = np.delete(train_user_data, indices, axis=0)\n",
        "    train_btc_meta_data = np.delete(train_btc_meta_data, indices, axis=0)\n",
        "    train_dates = np.delete(train_dates, indices)\n",
        "    train_matrices.shape, train_classes_t.shape, train_user_data.shape\n",
        "\n",
        "    indices = []\n",
        "    train_user_ids = np.unique(train_user_data[:,-1])\n",
        "    for i in range(len(test_user_data[:,-1])):\n",
        "        if test_user_data[i,-1] not in train_user_ids:\n",
        "            indices.append(i)\n",
        "\n",
        "    len(indices) / len(test_user_data[:,-1])\n",
        "\n",
        "    test_matrices = np.delete(test_matrices, indices, axis=0)\n",
        "    test_classes_t = np.delete(test_classes_t, indices)\n",
        "    test_classes = np.delete(test_classes, indices)\n",
        "    test_user_data = np.delete(test_user_data, indices, axis=0)\n",
        "    test_btc_meta_data = np.delete(test_btc_meta_data, indices, axis=0)\n",
        "    test_dates = np.delete(test_dates, indices)\n",
        "\n",
        "    return train_classes, train_user_data, train_matrices, train_dates, train_btc_meta_data, train_classes_t, test_classes, test_user_data, test_matrices, test_dates, test_btc_meta_data, test_classes_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqsmNbpbHB0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ['keywords_tfidf_p', 'count', True, False]\n",
        "def load_data_kfold(combination):\n",
        "    # Load matrices\n",
        "    train_classes, train_user_data, train_matrices, train_dates, train_btc_meta_data, train_classes_t, test_classes, test_user_data, test_matrices, test_dates, test_btc_meta_data, test_classes_t = load_matrices(combination)\n",
        "    # Preprocess data (remove test/train and normalize).\n",
        "    print('c1')\n",
        "    # create tensors etc\n",
        "    tensor_1 = torch.from_numpy(test_matrices)\n",
        "    tensor_2 = torch.from_numpy(test_classes_t) if multi_class else torch.from_numpy(test_classes)\n",
        "    tensor_3 = torch.from_numpy(test_user_data.astype(float))\n",
        "    tensor_4 = torch.from_numpy(test_dates.astype(float))\n",
        "    tensor_5 = torch.from_numpy(test_btc_meta_data.astype(float))\n",
        "\n",
        "    test = torch.utils.data.TensorDataset(tensor_1, tensor_2, tensor_3, tensor_4, tensor_5)\n",
        "\n",
        "    tensor_1 = torch.from_numpy(train_matrices)\n",
        "    tensor_2 = torch.from_numpy(train_classes_t) if multi_class else torch.from_numpy(train_classes)\n",
        "    tensor_3 = torch.from_numpy(train_user_data.astype(float))\n",
        "    tensor_4 = torch.from_numpy(train_dates.astype(float))\n",
        "    tensor_5 = torch.from_numpy(train_btc_meta_data.astype(float))\n",
        "\n",
        "    full_dataset = torch.utils.data.TensorDataset(tensor_1, tensor_2, tensor_3, tensor_4, tensor_5)\n",
        "\n",
        "    del train_classes, train_user_data, train_matrices, train_dates, train_btc_meta_data, train_classes_t, test_classes, test_user_data, test_matrices, test_dates, test_btc_meta_data, test_classes_t\n",
        "    \n",
        "    return full_dataset, test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFfQuQf0kWzT",
        "colab_type": "text"
      },
      "source": [
        "### Early stoppage class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKNuXdg29ToW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Early stops the training if validation loss dosen't improve after a given patience.\n",
        "    CREDITS GO TO: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
        "    \"\"\"\n",
        "    def __init__(self, patience=7, verbose=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "                            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        \n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "        \n",
        "        \n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).')\n",
        "        #torch.save(model.state_dict(), '/content/gdrive/My Drive/Colab Notebooks/data/btc/models/{}/{}/{}_checkpoint.pt'.format(model_type, batch_size, np.round(map_score, 3)))\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7fk-6q_JBwg",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXtUKCGUJD_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # Todo: add batchnorm for all layers?\n",
        "        self.conv1 = nn.Conv1d(INPUT_SIZE_CNN, 256, kernel_size=5, stride=1, padding=2) #+ 7\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(256, 128, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        \n",
        "        self.conv3 = nn.Conv1d(128, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        \n",
        "        self.conv4 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(64)\n",
        "        \n",
        "        self.fc1 = nn.Linear(5*64, 128)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.drop1 = nn.Dropout(0.5)\n",
        "        \n",
        "        self.fc2 = nn.Linear(128, 32)\n",
        "        self.bn6 = nn.BatchNorm1d(32)\n",
        "        self.drop2 = nn.Dropout(0.5)\n",
        "        \n",
        "        self.fc3 = nn.Linear(FCN_INPUT_SIZE, num_classes) # +  size_user_info\n",
        "        self.bn7 = nn.BatchNorm1d(num_classes)\n",
        "        self.drop3 = nn.Dropout(0.5)\n",
        "        \n",
        "        self.out_act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, user_data, btc_meta_data, batch_size, use_btc, use_user):\n",
        "        if use_btc:\n",
        "            x = torch.cat((x, btc_meta_data), 1)\n",
        "        x = x.view(batch_size, INPUT_SIZE_CNN, 7).float() #+ btc_meta_data.shape[1]\n",
        "        \n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.bn4(F.relu(self.conv4(x)))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        x = self.drop1(self.bn5(F.relu(self.fc1(x))))\n",
        "        x = self.drop2(self.bn6(F.relu(self.fc2(x))))\n",
        "        \n",
        "        if use_user:\n",
        "            x = torch.cat((x, user_data.float()), 1)\n",
        "        x = self.drop3(self.bn7(self.fc3(x)))\n",
        "        \n",
        "        if not multi_class:\n",
        "            x = self.out_act(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhn37Vq7K8vp",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate user-specific data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW6vWn4JLCGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score\n",
        "\n",
        "def validate_model(val_loader, multi_class, batch_size, combination):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = []\n",
        "        y = []\n",
        "        losses = []\n",
        "        for images, labels, user_data, dates, btc_meta_data in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            user_data = user_data.to(device)\n",
        "            btc_meta_data = btc_meta_data.to(device)\n",
        "            outputs = model(images, user_data, btc_meta_data, batch_size, combination[2], combination[3])\n",
        "            if multi_class:\n",
        "                loss = criterion(outputs, torch.max(labels, 1)[1].view(-1, 1))\n",
        "                pred.extend(torch.max(outputs, 1)[1].data.cpu().numpy())\n",
        "                y.extend(torch.max(labels, 1)[1].data.cpu().numpy())\n",
        "            else:\n",
        "                loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "                #pred.extend(outputs.data.cpu().numpy())\n",
        "                pred.extend([1 if x > 0.5 else 0 for x in outputs.data.cpu().numpy()])\n",
        "                y.extend(labels.data.cpu().numpy())\n",
        "            losses.append(loss.data.cpu().numpy())\n",
        "            \n",
        "        losses = np.mean(losses)\n",
        "      \n",
        "        if multi_class:\n",
        "            auc = accuracy_score(y, pred)\n",
        "        else:\n",
        "            auc = [precision_score(y, pred), recall_score(y, pred)]#average_precision_score(y, pred)\n",
        "\n",
        "        print('Epoch [{}/{}], val MAP/acc: {}, val loss: {}'\n",
        "              .format(epoch + 1, num_epochs, auc, losses))\n",
        "        \n",
        "        return losses, auc, y, pred\n",
        "\n",
        "def train_model(train_loader, multi_class, batch_size, combination):\n",
        "    losses = []\n",
        "    pred = []\n",
        "    y = []\n",
        "    model.train()\n",
        "    for i, (images, labels, user_data, dates, btc_meta_data) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        user_data = user_data.to(device)\n",
        "        btc_meta_data = btc_meta_data.to(device)\n",
        "        outputs = model(images, user_data, btc_meta_data, batch_size, combination[2], combination[3])\n",
        "        \n",
        "        if multi_class:\n",
        "            loss = criterion(outputs, torch.max(labels, 1)[1].view(-1, 1))\n",
        "            pred.extend(torch.max(outputs, 1)[1].data.cpu().numpy())\n",
        "            y.extend(torch.max(labels, 1)[1].data.cpu().numpy())\n",
        "        else:\n",
        "            loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "            #pred.extend(outputs.data.cpu().numpy())\n",
        "            pred.extend([1 if x > 0.5 else 0 for x in outputs.data.cpu().numpy()])\n",
        "            y.extend(labels.data.cpu().numpy())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        losses.append(loss.data.cpu().numpy())\n",
        "        \n",
        "        if i % int(len(train_loader) / 3)  == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, np.mean(losses)))\n",
        "\n",
        "    if multi_class:\n",
        "        auc = accuracy_score(y, pred)\n",
        "    else:\n",
        "        auc = [precision_score(y, pred), recall_score(y, pred)]#average_precision_score(y, pred)\n",
        "\n",
        "    return np.mean(losses), auc, y, pred\n",
        "\n",
        "def test_model(test_loader, multi_class, batch_size, combination):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = []\n",
        "        y = []\n",
        "        for images, labels, user_data, dates, btc_meta_data in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            user_data = user_data.to(device)\n",
        "            btc_meta_data = btc_meta_data.to(device)\n",
        "            outputs = model(images, user_data, btc_meta_data, batch_size, combination[2], combination[3])\n",
        "            if multi_class:\n",
        "                pred.extend(torch.max(outputs, 1)[1].data.cpu().numpy())\n",
        "                y.extend(torch.max(labels, 1)[1].data.cpu().numpy())\n",
        "            else:\n",
        "                #pred.extend(outputs.data.cpu().numpy())\n",
        "                pred.extend([1 if x > 0.5 else 0 for x in outputs.data.cpu().numpy()])\n",
        "                y.extend(labels.data.cpu().numpy())   \n",
        "      \n",
        "        if multi_class:\n",
        "            auc = accuracy_score(y, pred)\n",
        "        else:\n",
        "            auc = [precision_score(y, pred), recall_score(y, pred)]#average_precision_score(y, pred)\n",
        "\n",
        "        print('Test score: {}'.format(auc))\n",
        "        return auc, y, pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDUupONTK1nL",
        "colab_type": "text"
      },
      "source": [
        "### Aggregate users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UbwefSfCiKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def conf_matrix(combination, batch_size, conf_matrix, score_type):    \n",
        "    class_names=[0,1] # name  of classes\n",
        "    fig, ax = plt.subplots()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    # create heatmap\n",
        "    sns.heatmap(pd.DataFrame(conf_matrix), annot=True, fmt='g')\n",
        "    ax.xaxis.set_label_position(\"top\")\n",
        "#     plt.tight_layout()\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.savefig('/content/gdrive/My Drive/projects/data/btc/result_conf_matrix/{}_{}_{}_{}_{}_{}'.format(combination[0], combination[1], int(combination[2]), int(combination[3]), batch_size, score_type))\n",
        "    plt.close()\n",
        "\n",
        "def mean_pred_test(combination, train_df, test_df):\n",
        "    dates = test_df['date'].unique()\n",
        "    y_test = []\n",
        "    y_pred = []\n",
        "    for date in dates:\n",
        "        temp = test_df[test_df['date'] == date]\n",
        "        y_true = temp['true'].unique()[0]\n",
        "\n",
        "        max_out = temp['output'].mean()\n",
        "        #print(max_out)\n",
        "        max_all = 1.0 if max_out > 0.5 else 0.0\n",
        "        y_pred.append(max_all)\n",
        "        y_test.append(y_true)\n",
        "    #print(y_test, y_pred)\n",
        "    #conf_matrix(combination, y_test, y_pred)\n",
        "    return metrics.confusion_matrix(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred)\n",
        "\n",
        "def dataset_LR(train_df, test_df):\n",
        "    # Create dataset first.\n",
        "    train_users = train_df['user'].unique()\n",
        "    test_users = test_df['user'].unique()\n",
        "\n",
        "    users = np.concatenate((train_users, test_users))\n",
        "    user_ids_lr = {}\n",
        "    for i, v in enumerate(users):\n",
        "        user_ids_lr[v] = i\n",
        "\n",
        "    # Loop over dates, check if user has prediction\n",
        "    X_train = None\n",
        "    y_train = []\n",
        "    cnt = 0\n",
        "    for date in train_df['date'].unique():\n",
        "        cnt += 1\n",
        "        temp = train_df[train_df['date'] == date]\n",
        "        arr = np.zeros(len(users))\n",
        "        for row in temp.itertuples():\n",
        "            usr = row[3]\n",
        "            pred = row[1]\n",
        "            lbl = row[2]\n",
        "            arr[user_ids_lr[usr]] = pred\n",
        "        y_train.append([lbl])\n",
        "        if X_train is None:\n",
        "            X_train = arr\n",
        "        else:\n",
        "            X_train = np.vstack((X_train, arr))\n",
        "    \n",
        "    y_train = np.array(y_train)  \n",
        "\n",
        "    # Loop over dates, check if user has prediction\n",
        "    X_test = None\n",
        "    y_test = []\n",
        "\n",
        "    for date in test_df['date'].unique():\n",
        "        cnt += 1\n",
        "        temp = test_df[test_df['date'] == date]\n",
        "        arr = np.zeros(len(users))\n",
        "        for row in temp.itertuples():\n",
        "            usr = row[3]\n",
        "            pred = row[1]\n",
        "            lbl = row[2]\n",
        "#             try:\n",
        "            arr[user_ids_lr[usr]] = pred\n",
        "#             except:\n",
        "#                 continue\n",
        "                #print('User {} not found'.format(usr))\n",
        "#                 cnt_n += 1\n",
        "        y_test.append([lbl])\n",
        "        if X_test is None:\n",
        "            X_test = arr\n",
        "        else:\n",
        "            X_test = np.vstack((X_test, arr))\n",
        "\n",
        "    y_test = np.array(y_test)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "    \n",
        "    \n",
        "def LR(combination, train_df, test_df):    \n",
        "    X_train, y_train, X_test, y_test = dataset_LR(train_df, test_df)\n",
        "    # instantiate the model (using the default parameters)\n",
        "    logreg = LogisticRegression()\n",
        "\n",
        "    # fit the model with data\n",
        "    logreg.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = logreg.predict(X_test)\n",
        "    y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
        "    #print(y_pred_prob, y_test)\n",
        "    #conf_matrix(combination, y_test, y_pred)\n",
        "    return metrics.confusion_matrix(y_test, y_pred), precision_score(y_test, y_pred), recall_score(y_test, y_pred)\n",
        "\n",
        "def aggregate_evaluation_test(combination):\n",
        "    ## Create datasets.\n",
        "    train_lr = None\n",
        "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "    with torch.no_grad():\n",
        "        for images, labels, user_data, dates, btc_meta_data in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            user_data = user_data.to(device)\n",
        "            btc_meta_data = btc_meta_data.to(device)\n",
        "            outputs = model(images, user_data, btc_meta_data, batch_size, combination[2], combination[3])\n",
        "            predicted = torch.max(outputs, 1)[1].data.cpu().numpy()\n",
        "\n",
        "            outputs = np.array([x[0] for x in outputs.data.cpu().numpy()])\n",
        "            temp = np.dstack((outputs, labels.data.cpu().numpy(), \n",
        "                               user_data.data.cpu().numpy()[:,-1],\n",
        "                               dates.data.cpu().numpy(), predicted)).squeeze()\n",
        "            if train_lr is None:\n",
        "                train_lr = temp\n",
        "            else:\n",
        "                train_lr = np.concatenate((train_lr, temp), axis=0)\n",
        "                \n",
        "                \n",
        "    test_lr = None\n",
        "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "    with torch.no_grad():\n",
        "        for images, labels, user_data, dates, btc_meta_data in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            user_data = user_data.to(device)\n",
        "            btc_meta_data = btc_meta_data.to(device)\n",
        "            outputs = model(images, user_data, btc_meta_data, batch_size, combination[2], combination[3])\n",
        "            predicted = torch.max(outputs, 1)[1].data.cpu().numpy()\n",
        "\n",
        "            outputs = np.array([x[0] for x in outputs.data.cpu().numpy()])\n",
        "            temp = np.dstack((outputs, labels.data.cpu().numpy(), \n",
        "                               user_data.data.cpu().numpy()[:,-1],\n",
        "                               dates.data.cpu().numpy(), predicted)).squeeze()\n",
        "\n",
        "            if test_lr is None:\n",
        "                test_lr = temp\n",
        "            else:\n",
        "                test_lr = np.concatenate((test_lr, temp), axis=0)\n",
        "                \n",
        "    train_df = pd.DataFrame({'output':train_lr[:,0],'true':train_lr[:,1], \n",
        "                                   'user':train_lr[:,2], 'date':train_lr[:,3], 'pred_max':train_lr[:,4]})\n",
        "    test_df = pd.DataFrame({'output':test_lr[:,0],'true':test_lr[:,1], \n",
        "                                       'user':test_lr[:,2], 'date':test_lr[:,3], 'pred_max':test_lr[:,4]})\n",
        "    \n",
        "    mean_conf, mean_prec, mean_recall = mean_pred_test(combination, train_df, test_df)\n",
        "    LR_conf, LR_prec, LR_recall = LR(combination, train_df, test_df)\n",
        "    \n",
        "    return LR_conf, LR_prec, LR_recall, mean_conf, mean_prec, mean_recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXDNL7l2I7d4",
        "colab_type": "text"
      },
      "source": [
        "## Iterate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb54feAQeaBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LR_conf, LR_prec, LR_recall, mean_conf, mean_prec, mean_recall = aggregate_evaluation_test(combination)\n",
        "            \n",
        "# print('Finished fold, scores: {}'.format([LR_prec, LR_recall, mean_prec, mean_recall]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2AGZKdtaRag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper parameters\n",
        "num_epochs = 35\n",
        "batch_sizes = [128, 64, 512, 256, 1024, 2048]\n",
        "n_folds = 5\n",
        "multi_class = False\n",
        "num_classes = 1\n",
        "size_user_info = 8\n",
        "size_btc_md = 6\n",
        "patience_early_stopping = 1\n",
        "patience_reduce_lr = 1\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# Add combinations, make sure custom_features has 'count' due to mapping structure.\n",
        "# 20 tests in total, 8 each for TFIDF/TFIDF-P, 4 for custom features.\n",
        "# Booleans being the usage of btc meta-data and user meta-data or not.\n",
        "combinations = [['custom_features', 'count', False, False],\n",
        "               ['custom_features', 'count', True, False],\n",
        "               ['custom_features', 'count', False, True],\n",
        "               ['custom_features', 'count', True, True],\n",
        "                \n",
        "               ['keywords_tfidf', 'binary', False, False, 512],\n",
        "               ['keywords_tfidf', 'binary', True, False, 512],\n",
        "               ['keywords_tfidf', 'binary', False, True],\n",
        "               ['keywords_tfidf', 'binary', True, True],\n",
        "               \n",
        "               ['keywords_tfidf', 'count', False, False, 512],\n",
        "               ['keywords_tfidf', 'count', True, False],\n",
        "               ['keywords_tfidf', 'count', False, True],\n",
        "               ['keywords_tfidf', 'count', True, True],\n",
        "               \n",
        "               ['keywords_tfidf_p', 'binary', False, False, 512],\n",
        "               ['keywords_tfidf_p', 'binary', True, False],\n",
        "               ['keywords_tfidf_p', 'binary', False, True],\n",
        "               ['keywords_tfidf_p', 'binary', True, True],\n",
        "               \n",
        "               ['keywords_tfidf_p', 'count', False, False],\n",
        "               ['keywords_tfidf_p', 'count', True, False],\n",
        "               ['keywords_tfidf_p', 'count', False, True]]#,\n",
        "               ['keywords_tfidf_p', 'count', True, True]]\n",
        "\n",
        "prev_comb = [None, None, None, None]\n",
        "for combination in combinations:\n",
        "    print('-------------------------------')\n",
        "    print('-------------------------------')\n",
        "    print('STARTING NEW COMBINATION {}'.format(combination))\n",
        "    print('-------------------------------')\n",
        "    print('-------------------------------')\n",
        "    if prev_comb[0:2] != combination[0:2]:\n",
        "        if 'full_dataset' in globals():\n",
        "            del full_dataset\n",
        "\n",
        "        full_dataset, test_dataset = load_data_kfold(combination)\n",
        "    else:\n",
        "        prev_comb[0:2] = combination[0:2]\n",
        "\n",
        "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
        "    results = {}\n",
        "    for batch_size in batch_sizes:\n",
        "        INPUT_SIZE_CNN = 126 if 'custom' in combination[0] else 500\n",
        "        FCN_INPUT_SIZE = 32\n",
        "        \n",
        "        if combination[2] & combination[3]:\n",
        "            INPUT_SIZE_CNN = INPUT_SIZE_CNN + size_btc_md\n",
        "            FCN_INPUT_SIZE = FCN_INPUT_SIZE + size_user_info\n",
        "        elif combination[2] & (not combination[3]):\n",
        "            INPUT_SIZE_CNN = INPUT_SIZE_CNN + size_btc_md\n",
        "        elif (not combination[2]) & combination[3]:\n",
        "            FCN_INPUT_SIZE = FCN_INPUT_SIZE + size_user_info\n",
        "        \n",
        "        # Add learning rates that match the batch sizes.\n",
        "        print('-------------------------------')\n",
        "        print('Starting training for new batch size {}'.format(batch_size))\n",
        "        print('-------------------------------')\n",
        "        train_scores = []\n",
        "        val_scores = []\n",
        "        test_scores = []\n",
        "\n",
        "        test_agg = []\n",
        "        mean_conf_matrices = []\n",
        "        LR_conf_matrices = []\n",
        "        \n",
        "        test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              drop_last=True,\n",
        "                                              shuffle=False)\n",
        "#         print('a4')\n",
        "        for train_indexes, validation_indexes in kf.split(full_dataset):\n",
        "            train = torch.utils.data.dataset.Subset(full_dataset, train_indexes)\n",
        "            validation = torch.utils.data.dataset.Subset(full_dataset, validation_indexes)            \n",
        "#             print('a5')\n",
        "            # Add parameters for different model_combinations.\n",
        "            model = ConvNet(num_classes).to(device)\n",
        "            criterion = nn.BCELoss()\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "            early_stopping = EarlyStopping(patience=patience_early_stopping, \n",
        "                                           verbose=True)\n",
        "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
        "                                                       'min', verbose=True, \n",
        "                                                       patience=patience_reduce_lr)\n",
        "\n",
        "            # Set train and validation data loaders.\n",
        "            train_loader = torch.utils.data.DataLoader(dataset=train,\n",
        "                                                       batch_size=batch_size,\n",
        "                                                       drop_last=True,\n",
        "                                                       shuffle=True)\n",
        "            val_loader = torch.utils.data.DataLoader(dataset=validation,\n",
        "                                                      batch_size=batch_size,\n",
        "                                                      drop_last=True,\n",
        "                                                      shuffle=True)\n",
        "            del train, validation\n",
        "            \n",
        "            total_step = len(train_loader)\n",
        "            print('-------------------------------')\n",
        "            print('Starting training for new fold')\n",
        "            print('-------------------------------')\n",
        "            for epoch in range(num_epochs):\n",
        "                train_loss, train_score, _, _ = train_model(train_loader, multi_class,\n",
        "                                                         batch_size, combination)\n",
        "                val_loss, val_score, _, _ = validate_model(val_loader, multi_class, \n",
        "                                                         batch_size, combination)\n",
        "                print('At end of epoch, average (training) loss: {}, score: {} '.format(train_loss, train_score))\n",
        "                print('At end of epoch, average (validation) loss: {}, score: {} '.format(val_loss, val_score))\n",
        "                early_stopping(val_loss, model)\n",
        "                scheduler.step(val_loss)\n",
        "\n",
        "                if early_stopping.early_stop:\n",
        "                    print(\"EARLY STOPPAGE AFTER {} EPOCHS\".format(epoch))\n",
        "                    break\n",
        "            test_score, y, pred = test_model(test_loader, multi_class, batch_size, combination)\n",
        "            LR_conf, LR_prec, LR_recall, mean_conf, mean_prec, mean_recall = aggregate_evaluation_test(combination)\n",
        "            \n",
        "            print('Finished fold, scores: {}'.format([LR_prec, LR_recall, mean_prec, mean_recall]))\n",
        "            \n",
        "            train_scores.append(train_score)\n",
        "            val_scores.append(val_score)\n",
        "            test_scores.append(test_score)\n",
        "            test_agg.append([LR_prec, LR_recall, mean_prec, mean_recall])\n",
        "            mean_conf_matrices.append(mean_conf)\n",
        "            LR_conf_matrices.append(LR_conf)\n",
        "\n",
        "        # Take means and add to dict.\n",
        "        results[batch_size] = [np.mean(train_scores, axis=0), np.mean(val_scores, axis=0), \n",
        "                               np.mean(test_scores, axis=0), np.mean(test_agg, axis=0)]\n",
        "\n",
        "        # Save confusion matrix as mean of all folds.\n",
        "        conf_matrix(combination, batch_size, np.mean(LR_conf_matrices, axis=0), 'LR')   \n",
        "        conf_matrix(combination, batch_size, np.mean(mean_conf_matrices, axis=0), 'mean')\n",
        "        \n",
        "        print('-------------------------------')\n",
        "        print('{}-fold validation has been executed, mean LR_prec, LR_recall, mean_prec, mean_recall: {}'.\n",
        "              format(n_folds, np.mean(test_agg, axis=0)))\n",
        "        \n",
        "        \n",
        "    # Save results for model type and all batch size combinations.\n",
        "    np.save('/content/gdrive/My Drive/projects/data/btc/results/{}_{}_{}_{}'.format(combination[0], combination[1], int(combination[2]), int(combination[3])), np.array(results))\n",
        "    print('Saved results')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3HJtXIG39gp",
        "colab_type": "text"
      },
      "source": [
        "# Process final results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20IGXoXG4Aul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_str = '/content/gdrive/My Drive/Colab Notebooks/data/btc/results/'\n",
        "files = os.listdir(base_str)\n",
        "\n",
        "results = {}\n",
        "for file in files:\n",
        "    results[file.strip('.npy')] = np.load(base_str + file)[()] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gCXakzV41PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# method, batch_size, train_map, val_map, test_map, test_lr, test_mean_pred.\n",
        "columns = ['Experiment', 'Batch_size', 'type', 'user_meta_data', 'Train Precision', 'Train Recall', 'Val Precision', 'Val Recall', 'Test Precision', 'Test Recall',\n",
        "          'LR Precision', 'LR Recall', 'Mean Precision', 'Mean Recall']\n",
        "final = []\n",
        "for k in results.keys():\n",
        "    for batch_size in [32, 64, 128, 256, 512]:\n",
        "        k_replaced = k.replace('keywords_', '').replace('_count_', '').replace('_binary_', '')[:-3]\n",
        "\n",
        "        t = 'Binary' if 'binary' in k else 'Count'\n",
        "        b = 'Yes' if k[-3] == '1' else 'No'\n",
        "        u = 'Yes' if k[-1] == '1' else 'No'\n",
        "        merge = [item for sublist in results[k][batch_size] for item in sublist]        \n",
        "        temp = [k_replaced, batch_size, t, u]\n",
        "        temp.extend(merge)\n",
        "        # train_map, val_map, test_map, test_lr, test_mean_pred.\n",
        "        final.append(temp)\n",
        "        \n",
        "# Booleans being the usage of btc meta-data and user meta-data or not.\n",
        "final = pd.DataFrame.from_records(final, columns=columns)\n",
        "final['Experiment'][final['Experiment'] == 'tfidf_p'] = 'Partial TF-IDF'\n",
        "final['Experiment'][final['Experiment'] == 'tfidf'] = 'TF-IDF'\n",
        "final = final[final['Experiment'] != 'custom_features']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHGUiZI55ia5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Personally went through all combinations of experiments, types, btc meta data and user meta data to find the max scores.\n",
        "a = final[(final['Experiment'] == 'Partial TF-IDF') & (final['type'] == 'Binary') \n",
        "      & (final['user_meta_data'] == 'No')]\n",
        "\n",
        "a.sort_values(['LR Precision', 'Mean Precision'], ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}