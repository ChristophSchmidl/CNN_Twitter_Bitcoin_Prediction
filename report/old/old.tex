\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage[table,xcdraw]{xcolor}
\usepackage{cite}
\usepackage{float}
\usepackage{caption}
\usepackage{parskip}
\usepackage{subcaption}
\usepackage{lscape}
\usepackage{longtable}

\usepackage{graphicx}
\graphicspath{ {images/} }

\title{Trading Bitcoin based on Twitter messages}
% Predicting Bitcoin fluctuations based on the stance of Twitter users}
% Trading Bitcoin by encapsulating Twitter user's stance in matrices
% Trading Bitcoin based on temporal information of Twitter users
% Predicting Bitcoin fluctuations based on the stance of Twitter users
% A convolutional approach to predicting Bitcoin fluctuations
\author{Mick van Hulst (s1013954)}
\begin{document}
\maketitle

\begin{abstract}
This paper introduces a method for Bitcoin price prediction based on user-specific keyword usage of Twitter messages (also known as 'Tweets'). The purpose of this research is to show if predictions regarding the Bitcoin price can be made by utilizing textual relationships of Twitter messages for specific users. We instantiate matrices that are specific to a user's Tweets over a set amount of time. These matrices are used to train a CNN, which predict whether or not a profitable trade can be made for the following day. We map the keyword usage of users to matrices by employing TF-IDF, which is a general technique that's used for finding words of importance in a set of documents (i.e. tweets in our case). We measure succes by using the Mean Average Precision (MAP). Furthermore, we utilize a simple trading strategy which aggregates predictions of all users for specific days into a single prediction to observe whether or not the combined force of users increases our odds of making a profit. We utlize a baseline, consisting of several hand-made features and try to beat it using the TF-IDF generated matrices. We find that partial TF-IDF matching works best etc.
\end{abstract}

\section{Introduction}
In 2008 the peer-to-peer electronic cash system called Bitcoin was introduced by Satoshi Nakamoto \cite{Nakamoto_bitcoin:a}. In the following years, Bitcoin increased in value and popularity. With the increasing popularity of social media, one would assume that the popularity of Bitcoin would be epxressed on social media. Kaminski \cite{1406.7577} suggests that the Twitter platform may be interpreted as a virtual trading floor that emotionally reflects Bitcoin's market movement. This work focuses on capturing this market movement by gathering Tweets from a set of users and embeddings keywords of user-specific tweets for a time period in matrices, such that models can be trained to predict whether or not the price of Bitcoin will go up or not.

CNNs have previously been used for causes where the data consisted of spatial relationships such as AlexNet, a convolutional neural net that predicted class labels of (ImageNet) images \cite{NIPS2012_4824}. The structure of a CNN, however, can also be changed to a one-dimensional sequence. This allows the CNN to be used more generally on other types of data that have a spatial relationship. For example, there's an ordered relationship in the time steps of a time series \cite{machine_learning_mastery_2018}. The problem that is tackled in this work also consists of a time series, which is why one-dimensional CNNs are utilized.

\textbf{MAKE SURE THAT THE GOAL IS CLEAR. WE ARE TRYING TO FIND PATTERNS IN THE USAGE OF SPECIFIC WORDS FOR SPECIFIC USERS, HENCE WHY USER META-DATA CAN BE OF IMPORTANCE.}


The research question that this work attempts to tackle is: \\
\textit{Can, given a set of tweets of specific Twitter mess}

\textit{Can we, given a set of tweets of specific twitter users, make a (Hypothetically) profitable trade for Bitcoin?}

\section{Related work}
As mentioned in the introduction, Kaminski \cite{1406.7577} concludes that the Twitter platform may be interpreted as a virtual trading floor that emotionally reflects Bitcoin's market movement. Here, Kaminski also mentions that the Granger causality analysis shows that there is no statistical significance for Twitter signals with regard to the close price, intraday spread or intraday return. Kennis \cite{1811.03146} further analyzes media sources like Reddit and finds weak correlations regarding the sentiment of these sources and price movements. Hernandez et al. \cite{inproceedings} mention that (Twitter) Bitcoin users are less likely to use emotion related words in their tweets, which could help explain why Kaminski's and Kennis's work show that there is no correlation between the general sentiment of Twitter users and Bitcoin price fluctuations (\textbf{CHECK THERE WORK TO SEE WHAT THEY DID AGAIN}). Sul et al.  \cite{sul2017trading} mention that three is a correlation between certain meta-data and sentiment of users being used for predictive purposes of stock market prices. This prior work raises the hypothesis that it might be more beneficial to predict Bitcoin prices by focusing on user-specific messages and that the general stance of Twitters users cannot be captured generally, meaning that without user-specific information, relationships are not portrayed sufficiently in the data and can thus not act as an indicator for Bitcoin price changes.

In terms of trading strategies, Hoseinzade et al. \cite{1810.08923} released a paper that used certain stock market indicators and CNNs to predict price fluctuations. For Bitcoin specific trading, Hotz-Behofsits et al. \cite{1801.06373} developed non-Gaussian state space models and focused on the daily change in the log price of Bitcoin, Ethereum and Litecoin. They developed a simple trading strategy for the optimization of portfolio allocation. For Bitcoin specific trading there is one interesting mention that, according to their results, achieved great success. This paper was released by Devavrat et al. \cite{1410.1231} and used data coming from the order book of the exchange 'Okcoin.com' to perform Bayesian regression such that the model gave indications as to whether or not they should buy, sell or hold Bitcoin. After 60 days, they claim to have doubled their investment.

Although some work has been done prior to this work, no trading model for Bitcoin has been released that is based on Twitter data. This work is intended as a baseline for future work.

\section{Approach}
\subsection{Data}
\subsubsection{Data Gathering}
We base our data gathering method on prior work \cite{sul2017trading}. This work mentions that Twitter users, use a dollar sign and a shortcut of a certain stock as an indication that they are talking about that particular stock. In the case of this work, this means that Twitter messages are collected that contain '\$btc' (not capital letter sensitive). After collecting data between the period of 26th of September (2018) to the 2nd of January (2019), the tweets are processed and unique usernames are gathered. Iterating over each user and gathering all their tweets that contain the aforementioned keyword results in the final dataset\footnote{This approach was used due to Twitter limiting access to historical data (scraping can be done up to 14 days back in time)}. The resulting Twitter messages were preprocessed by removing Retweets, tweets with more than one ticker symbol sign\footnote{According to Sul et al. \cite{sul2017trading} multiple ticker symbols makes it hard to differentiate between  ticker symbols and derive which one the message is about.} (e.g. \$ETH for Ethereum), URLs, mentions, excessive characters (e.g. 'goood' is transformed to 'good'), unicode characters, stopwords, digits that indicated a price and punctuations. Lastly, all characters were converted to lower-case characters and all tweets prior to June 1st 2017 were removed \textbf{(ADD DISTRIBUTION IMAGE)}. 

Besides Twitter messages, additional data sources include:
\begin{itemize}
    \item Meta-data for users, which is included when retrieving Tweets using the Twitter API. As a user's meta-data changes overtime, only the most recent meta-data for a particular user is used. \textbf{Mention what data was used.}
    \item Meta-data for Bitcoin. Historical Bitcoin meta-data is retrieved from CryptoDataDownload \cite{cryptodatadownload}, which is a platform that aims to provide free historical data for several cryptocurrencies. Preprocessing the Bitcoin data consisted of adding columns with respect to fluctuations of prices and volume. This is used to determine whether or not a trade prior to that day would have been profitable. As Bitcoin prices can differ per platform, this work focuses on Coinbase's price fluctuations \cite{coinbase_pro}. Determining whether or not a trade was profitable is based on taking the difference between the Bitcoin price of two days, applying a fee that is paid when making a trade and then determining whether or not the result of the calculation is positive or not. \textbf{mention what data was used.}
\end{itemize}
After the preprocessing of the data, the data is split into a training and test set. Before splitting, the data is ordered such that the test data consists of data coming from dates that are not in the training data (i.e. a clear temporal cut). The test data consists of a total of around two months of data (1st of November 2018 to the 2nd January 2019). The last preprocessing step includes the removal of all users that are not both in the training and test data. 

\subsubsection{Matrices}
CNNS require a matrix as input. The idea here is to capture some form of a pattern over a fixed amount of time, where tweets contain words and/or specific characterics that are informative for Bitocin price fluctuations. The matrices exist of the amount of features as rows and the amount of timesteps as columns. This way, a time series is created that captures the change in features for a specific amount of timesteps.

First, TF-IDF was used to first find a list of 500 words which are important according to the method. These words were used as individual rows for the matrices. Second, the amount of columns for a matrix is fixed to 7, meaning that a matrix consists are of shape (500, 7). Third, tweets are represented in the aforementioned matrices by processing tweets for specific users of specific dates and seeing whether or not the words for a specific date occur in the tweet. To create a single matrix, this last step is repeated 7 times for each specific date. The final matrix captures the change in specific word usage for a user over a period of 7 days. Using the aforementioned method, four types of matrices are created. The first matrix, is a binary matrix that has zeroes and ones, where ones represent a TF-IDF word occurring for tweets of a specific user and date combination, and where a one means that there is a full match between the tweet and TF-IDF (i.e. meaning that the word 'fear' only matches 'fear' and not 'fearful). The second matrix is similar to the previous matrix, but instead of being binary, it counts the occurrences of a word in a tweet, meaning that matrices do not solely consist of zeroes and ones. The third and fourth matrix is similar to the aforementioned matrices, but now uses partial matching, meaning that a word like 'fear' also matches 'fearful' as 'fear' is a subword of 'fearful'. Instead of partial matching, stemming could have been an option, but stemming reduces words as "universal" and "university" to 'univers' (\textbf{SRC} Porter Stemmer). Partial matching does not suffer from this problem as 'university' is not a subword of 'universe and vice versa.

Besides the matrices that were generated using tweets, additional matrices were created using BTC meta-data. Matrices here consisted of the change in the aforementioned data and for the same timespan as the other matrices. Furthermore, user meta-data and classes were not processed in matrices as this does not include a spatial relationship. User meta-data was concatenated in the network, which will be discussed in the next section. The classes were created by storing whether or not a trade would have been profitable the day after the last day of the matrix.

Table \textbf{1} shows the total amount of matrices that were gathered per type of matrix representation. Here it is important to mention that the amount of matrices per matrix representation differs, this is due to matrices only being filled if they are non-zero, which is not always the same as it might be the case that none of the words is in the keyword list for TF-IDF.

% - TFIDF, also count vs binary.
% - TFIDF partial, also count vs binary.
% - Custom feature set.

% CNNs use matrices which are convoluted over to get to a final result. In our case, these matrices consist of a n by t matrix, where n represents the occurrences of words in our list of TF-IDF words\footnote{Note that for TF-IDF we test both partial and full matching, which will be elaborated on in the Experiments}.  The list of words is aggregated per user and per day, meaning that if a user tweets several times per day, these tweets are merged. Furthermore, t represents the dates that are represented as columns. The amount of columns is set to either 7 or 30 to test for longer term dependencies. Generation of our matrices can be described using the following steps.
% \begin{enumerate}
%     \item Get the dates of the first and last tweet of our dataset. Subtract t days from the first tweet, such that we have a buffer.
%     \item Iterate over all dates, where we 1) get all unique users that tweeted on that particular day and 2) create an interval of $[t-interval, t]$. We apply this method as in a real world scenario we'd check which users tweeted on a particular day and then get all their tweets of previous days to try to predict whether the price goes up the following day.
%     \item For each date in our interval, we iterate over our unique list of users and create matrices that represent their activities over that time interval. Their activities are registered as either occurrences in our TF-IDF keywords list or the keyword clustering centroids.
%     \item When saving the keyword matrice, we also save: user meta-data, date indicator and the binary class of the matrix (the price of bitcoin going up or down at t+1).
%     \item One could argue that it would be interesting to focus on all Twitter messages for a specific word to predict the price of Bitcoin going up or not. This, however, would make it problematic when generating a large enough data set for the CNN to train on. We show this by example: we assume we have 365 data points consisting of price changes. If we focus on the entire Twitter population, we'd have $365-t$ data points, where t equals the size of our time frame. By focusing on user-specific prediction, we can, in the optimal scenario, increase our data set size to $(365-t)u$, where u is our amount of users (assuming that all users tweeted every single day).
% \end{enumerate}
% \textbf{An idea for the matrix visualization could be to just take the average of all matrices for a particular class and visualize those.}


% Figure \textbf{a and b} show examples of four matrices (\textbf{both test and train}), where we see that there aren't many occurrences of words in matrices. To ensure that there's signal in the matrices which the CNNs can use, we also employ partial matching (meaning that e.g. keyword 'fear' also matches 'fearful') and experiment with this separately (see \textbf{fig} for matrices). The aforementioned figure represents a binary representation of our matrices, we also experiment with counts of words, which are shown in figure \textbf{ref}.

% \textbf{Mention that there is not a class imbalance between training and test matrices on a user/date basis. However, once this is aggregated per date, then there is an imbalance, which could be an indication that users tweet more when the price is up, which results in more tweets with label 1, while aggregation still results in just a 1 for 1 date.}

\subsection{Experimental setup}
The CNN that was used consisted of one-dimensional convolutional layers, where 

- Mention normalization of data itself
- Mention dropout and batch-normalization.
- Mention concatenation and test of btc meta-data
- Mention experimental setup


Talk about how I use the different representations in the CNNs and how the CNNs are designed. Mention 1d CNN and why (\textbf{Note: currently experimenting with several designs, will explain this later on.}).

Daily classifications for several users. We develop a trading strategy using logistic regression and by combining the strength of all users into one. Furthermore, we also take the mean of all predictions for a day to see if the errors cancel each other out.


We use the \textbf{MEAN AVERAGE PRECISION} score. The reason for this is because we treat our problem as binary classification, meaning that 1 means that we would have made a trade, while 0 means that we would not have made a trade. Although not trading also means losing out of money, it does not reduce the total capital, which means that we go to far as to assume that the cost of a false positive is higher than a false negative. In comparison to, for example, the AUC-ROC score, MAP score for this reason seems like a better fit. Another reason to not use AUC-ROC score is that it is vulnerable to class imbalance, which is not something that we experience for our user-date matrices, but it is something we experience when aggregating per date \textbf{ref}.

\subsection{Implementation details}
CNNs, nowadays, tend to have a high amount of parameters. This research aims to focus on CNNs with a lower amount of parameters to reduce training time. We feel, this is of importance when developing a trading method, as we need to continuously retrain our network with newly available data, meaning that retrainability is highly important. In terms of research purposes, this allows us to perform K-fold cross-validation (with $K=3$). \textbf{Mention that I use the validation set to autostop, which reduces the chances of overfitting (\textbf{SRC??}).}

\textbf{Mention trading strategy}

\section{Results}
Solely report results for both trading strategy etc.

In total we perform 80 experiments (\textbf{Mention combinations and batch size}), but for readability reasons we limit ourselves to reporting the best performing batch size for a particular experiment combination. In this case, 'best performing' means that if we were to make a trade, it would have been profitable. In such a case this means that the trading strategy, aggregated for all users on a daily basis has to be the highest. Table \textbf{blah} shows the final results.

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{llllllllll}
\hline
\textbf{Model}    & \textbf{Type}   & \textbf{BTC MD} & \textbf{User MD} & \textbf{Batch size} & \textbf{Train} & \textbf{Val} & \textbf{Test} & \textbf{Test LR} & \textbf{Test Mean} \\ \hline
\textbf{P TF-IDF} & \textbf{Binary} & No              & No               & 64                  & 0.62           & 0.47         & 0.43          & 0.5              & 0.43               \\
                  &                 & Yes             & No               & 64                  & 0.45           & 0.45         & 0.43          & 0.42             & 0.42               \\
                  &                 & No              & Yes              & 32                  & 0.59           & 0.47         & 0.43          & \textbf{0.49}    & 0.41               \\
                  &                 & Yes             & Yes              & 32                  & 0.45           & 0.45         & 0.43          & 0.42             & 0.43               \\
                  & \textbf{Count}  & No              & No               & 256                 & 0.65           & 0.47         & 0.43          & 0.56             & 0.45               \\
                  &                 & Yes             & No               & 128                 & 0.45           & 0.45         & 0.43          & 0.42             & 0.43               \\
                  &                 & No              & Yes              & 128                 & 0.63           & 0.47         & 0.43          & \textbf{0.57}    & 0.44               \\
                  &                 & Yes             & Yes              & 256                 & 0.45           & 0.45         & 0.43          & 0.42             & 0.43               \\
\textbf{TF-IDF}   & \textbf{Binary} & No              & No               & 512                 & 0.71           & 0.45         & 0.41          & 0.36             & 0.49               \\
                  &                 & Yes             & No               & 128                 & 0.44           & 0.44         & 0.43          & 0.42             & \textbf{0.54}      \\
                  &                 & No              & Yes              & 512                 & 0.79           & 0.45         & 0.42          & 0.41             & 0.47               \\
                  &                 & Yes             & Yes              & 512                 & 0.45           & 0.45         & 0.43          & 0.49             & 0.53               \\
                  & \textbf{Count}           & No              & No               & 512                 & 0.69           & 0.45         & 0.42          & 0.38             & 0.48               \\
                  &                 & Yes             & No               & 512                 & 0.43           & 0.44         & 0.42          & 0.4              & \textbf{0.54}      \\
                  &                 & No              & Yes              & 512                 & 0.64           & 0.46         & 0.42          & 0.38             & 0.48               \\
                  &                 & Yes             & Yes              & 512                 & 0.45           & 0.45         & 0.43          & 0.46             & 0.53               \\ \hline
\end{tabular}%
}
\end{table}


% \subsubsection{TFIDF}
% Test binary, count and influence of user information. That's four experiments in total. Then also do the same
% for 30 days, making it a total of 8 experiments, where we display graphs of the losses in 1 figure and the resulting 
% accuracy on the validation set (PERFORM K-FOLD CROSS-VAL).

% Make a separate table where we use all results for the 8 different models to then make a single prediction on the validation set of the best performing k-fold cross-validation set on a day-by-day level. 

% \subsubsection{Trading strategy}
% Pick the best ones 

% Experimental setup (repeat all for several settings).:
% 1) TF-IDF binary word occurrences (i.e. even if a word occurs more than once, the matrix will still save 
% 2) TF-IDF counts of word occurrences (i.e. in contrast to 1, the matrix will now save the count).
% 3) Add user meta-data and compare results.
% 4) Add BTC meta-data and compare results.
% 5) repeat steps for TF-IDF partial matching.
% 6) Make a final trading strategy based on results.

% Argue differences between count/binary, full/partial matching and meta-data.

\section{Discussion}

\section{Conclusion}

\section{Future research}
\begin{itemize}
    \item Multi-label could be interesting.
    \item amount of data is relatively small.
    \item longer time intervals (i.e. 30 days).
    \item More complex trading strategies.
    \item Different types of representation such as features that perform word, character counts and or perhaps a POS-tagger.
\end{itemize}


% Perhaps the strategy that's closest to our work would be PredCNN \cite{1810.08923}. The idea of using certain technical indicators is interesting there might be room for a multimodal approach We feel that combining such methods with our method to create a multimodal approach could be interesting.

% Future research does not solely entail new algorithmic approaches, but should most definitely include exploring various data sources and methods of preprocessing and structuring of data.

% \textbf{MAKE SURE TO CHECK EMAIL ABOUT REFERENCES AT THE END.\textbf{}}

% Our research, for convenience, decided to focus on whether or not the price of Bitcoin would go up, where we inherently made the wrong assumption that 'Bitcoin going up' is the only way to trade. This, however, is absolutely false and was just an assumption for, as we mentioned, convenience reasons. In future research, we'd like to extend this work to a multi-modal approach, where we also look at, for example, shorting. This means, that if we have a strong signal that Bitcoin will be going down, we'd actually perform a short trade and earn that way. This would increase the potential of our trading strategy and would make it possible to trade in periods of grief for many traders (i.e. the investors that went long on Bitcoin in e.g. January, sorry people..).

% I also experimented with a 3 class problem. When comparing the binary problem to a three class problem, we could simply state that we compare them in ways that we would have made a profit. In the three class problem, there are more opportunities to make money, but also more opportunities to lose money. This way we can essentially reduce this to a binary measure, where we either would have lost money by making our bet or missed an opportunity to make money by not making a bet. One has to note here that the option of doing nothing, is not counted as making money nor is it counted as losing money. This action can be considered neutral. However, saying that it we should not trade, while we actually should have traded, is counted as a loss as this was an opportunity to make money.

\textbf{CHANGE TO APA IF NECESSARY. IN SUCH A CASE THE APACITE THINGY (SEE SIMULATION PROJECT) AUTOMATICALLY ORDERS BY DATE.}

\bibliographystyle{plain}
\bibliography{mybib}

\end{document}